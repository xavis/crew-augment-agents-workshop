{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "josoDO7OVISN"
      },
      "source": [
        "# ğŸ¤– Gemini Multi-Agent workshop - Type 1\n",
        "\n",
        "This notebook sets up a hierarchical agent team using **CrewAI** and **Google Gemini 2.5 Flash**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XaN-DwVrVISO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee866ff-7fe6-45c8-b975-f8fd6e84c570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.12/dist-packages (0.7.21)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.5)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.8.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.9.11)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (4.15.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.12/dist-packages (8.1.1)\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.2.7)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Downloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: socksio, fake-useragent, ddgs\n",
            "Successfully installed ddgs-9.10.0 fake-useragent-2.2.0 socksio-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q crewai crewai_tools langchain-google-genai\n",
        "!pip install tavily-python\n",
        "!pip install -U langchain-community duckduckgo-search ddgs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from crewai.tools import tool\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai_tools import TavilySearchTool\n",
        "\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "xmrSwYATVKTH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL_ID\"] = 'gemini/gemini-2.5-flash'\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "DQVsSy7WVMXI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERBOSE = True\n",
        "\n",
        "tools = dict()\n",
        "tasks = []"
      ],
      "metadata": {
        "id": "mZ_HHyYRk7-8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T97DLJgbVISP"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Load and configure the Large Language Model (LLM) connector\n",
        "# -----------------------------------------------------------\n",
        "# This initializes a connection to a Gemini model using the\n",
        "# model identifier stored in an environment variable.\n",
        "#\n",
        "# Environment variables are used so that model selection can\n",
        "# be changed without modifying the code (useful for staging,\n",
        "# production, or experimentation).\n",
        "#\n",
        "# The temperature parameter controls randomness:\n",
        "# - Lower values (e.g., 0.2) â†’ more deterministic responses\n",
        "# - Higher values (e.g., 0.9) â†’ more creative/diverse output\n",
        "#\n",
        "# Additional parameters below allow fine-grained control over:\n",
        "# - response length\n",
        "# - sampling behavior\n",
        "# - reproducibility\n",
        "# - safety limits\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "tools['gemini_llm'] = LLM(\n",
        "    model = os.environ[\"MODEL_ID\"],   # Model name/version loaded securely from environment\n",
        "    temperature = 0.7,                # Creativity level (balanced between accuracy and diversity)\n",
        "\n",
        "    # --- Optional advanced generation controls ---\n",
        "\n",
        "    max_tokens=1024,                  # Maximum number of tokens allowed in the response\n",
        "    top_p = 0.9,                      # Nucleus sampling: restricts token selection to top probability mass\n",
        "    top_k = 40,                       # Limits sampling to top-k most likely tokens\n",
        "    frequency_penalty = 0.2,          # Reduces repetition of previously used words\n",
        "    presence_penalty = 0.1,           # Encourages introducing new topics/content\n",
        "\n",
        "    # --- Stability & runtime behavior ---\n",
        "\n",
        "    timeout = 30,                     # Request timeout in seconds\n",
        "    seed = 42,                        # Fixed seed for reproducible outputs (optional)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# Initialize external research/search tool\n",
        "# -----------------------------------------------------------\n",
        "# This tool allows agents to perform real-time web searches.\n",
        "# It extends the agentsâ€™ capabilities beyond the base LLM by\n",
        "# giving access to fresh, external information.\n",
        "#\n",
        "# Useful for:\n",
        "# - fact-checking\n",
        "# - market research\n",
        "# - trend analysis\n",
        "# - retrieving up-to-date data\n",
        "#\n",
        "# Tools like this act as â€œsensorsâ€ for agents, enabling them\n",
        "# to gather evidence before generating responses.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "tools['tavily'] = TavilySearchTool()"
      ],
      "metadata": {
        "id": "pAWwt5gwlZuA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# Register DuckDuckGo search tool\n",
        "# -----------------------------------------------------------\n",
        "# This adds a web search capability to the shared tools\n",
        "# registry under the key 'ddg'.\n",
        "#\n",
        "# Tools stored in a dictionary can be dynamically assigned\n",
        "# to agents or tasks later in the workflow.\n",
        "#\n",
        "# DuckDuckGo search provides lightweight, privacy-focused\n",
        "# web results and is useful for:\n",
        "# - quick lookups\n",
        "# - news discovery\n",
        "# - fact validation\n",
        "# - supplemental research\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "@tool('DuckDuckGoSearch')\n",
        "def duckduckgo_search(search_query: str):\n",
        "    \"\"\"Search the web for information on a given topic using DuckDuckGo.\"\"\"\n",
        "    return DuckDuckGoSearchRun().run(search_query)\n",
        "\n",
        "tools['ddg'] = duckduckgo_search"
      ],
      "metadata": {
        "id": "XgBBQH9CnyqK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# Register Calculator tool\n",
        "# -----------------------------------------------------------\n",
        "# This adds a mathematical computation capability to the\n",
        "# shared tools registry under the key 'calc'.\n",
        "#\n",
        "# Calculator tools allow agents to perform precise numeric\n",
        "# reasoning instead of approximating math with an LLM.\n",
        "#\n",
        "# Useful for:\n",
        "# - arithmetic operations\n",
        "# - financial calculations\n",
        "# - statistics\n",
        "# - unit conversions\n",
        "# - engineering/scientific formulas\n",
        "#\n",
        "# This improves accuracy and prevents hallucinated math.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "@tool('Calculator')\n",
        "def calculator(expression: str):\n",
        "    \"\"\"\n",
        "    Evaluate a mathematical expression safely and return the result.\n",
        "    The input should be a valid arithmetic expression.\n",
        "    Example: \"25 * 4 + 10 / 2\"\n",
        "    \"\"\"\n",
        "    return eval(expression)\n",
        "\n",
        "\n",
        "tools['calc'] = calculator"
      ],
      "metadata": {
        "id": "dIdQqyxKqejO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# Define Researcher Agent\n",
        "# -----------------------------------------------------------\n",
        "# This agent is responsible for gathering up-to-date,\n",
        "# evidence-based information before content creation.\n",
        "#\n",
        "# Unlike the writer, this agent is tool-enabled and can\n",
        "# perform live searches to retrieve current data.\n",
        "#\n",
        "# It acts as the intelligence-gathering component of the\n",
        "# system, ensuring outputs are grounded in recent research.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "researcher_1 = Agent(\n",
        "    role = 'Senior Research Analyst 1',\n",
        "    # Defines the agentâ€™s expertise and authority level.\n",
        "    # Encourages analytical, fact-driven reasoning.\n",
        "\n",
        "    goal = 'Find the latest breakthroughs in {topic}',\n",
        "    # Primary mission: identify cutting-edge developments.\n",
        "    # {topic} will be dynamically injected at runtime.\n",
        "\n",
        "    backstory = 'You are an expert researcher with a focus on 2026 tech trends.',\n",
        "    # Behavioral prompt shaping the agentâ€™s mindset.\n",
        "    # Emphasizes forward-looking, trend-aware research.\n",
        "\n",
        "    tools = [tools['tavily']],\n",
        "    # Grants the agent access to external search capabilities.\n",
        "    # Tools extend the agent beyond static LLM knowledge.\n",
        "    # The agent can call Tavily to fetch real-time web data.\n",
        "\n",
        "    llm = tools['gemini_llm'],\n",
        "    # Core language model used for reasoning and synthesis.\n",
        "\n",
        "    verbose = True\n",
        "    # Enables detailed execution tracing.\n",
        "    # Useful for debugging research steps and tool usage.\n",
        ")"
      ],
      "metadata": {
        "id": "Evtx_sCvWpmg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# Define Researcher Agent (DuckDuckGo-powered version)\n",
        "# -----------------------------------------------------------\n",
        "# This agent specializes in real-time research using an\n",
        "# external search tool. It focuses on discovering cutting-\n",
        "# edge developments and synthesizing current information.\n",
        "#\n",
        "# Compared to a static LLM-only agent, this researcher can\n",
        "# actively query the web, making it suitable for trend\n",
        "# analysis and time-sensitive insights.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "researcher_2 = Agent(\n",
        "    role = 'Senior Research Analyst 2',\n",
        "    # Establishes authority and analytical expertise.\n",
        "    # Encourages evidence-driven reasoning and structured research.\n",
        "\n",
        "    goal = 'Find the latest breakthroughs in {topic}',\n",
        "    # Core mission of the agent.\n",
        "    # {topic} will be dynamically injected during execution.\n",
        "\n",
        "    backstory = 'You are an expert researcher with a focus on 2026 tech trends.',\n",
        "    # Behavioral context guiding style and priorities.\n",
        "    # Promotes forward-looking, innovation-focused research.\n",
        "\n",
        "    tools = [tools['ddg']],\n",
        "    # Grants access to the DuckDuckGo search tool.\n",
        "    # Wrapped in a list because agents can support multiple tools.\n",
        "    # Enables live external research during reasoning.\n",
        "\n",
        "    llm = tools['gemini_llm'],\n",
        "    # Language model used for interpretation and synthesis.\n",
        "    # Retrieved from the shared tools/config registry.\n",
        "\n",
        "    verbose = True\n",
        "    # Enables detailed execution logs.\n",
        "    # Useful for debugging agent decisions and tool calls.\n",
        ")"
      ],
      "metadata": {
        "id": "LtfhavnJoB-t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# Define Hybrid Research + Calculator Agent\n",
        "# -----------------------------------------------------------\n",
        "# This agent combines live research capabilities with\n",
        "# deterministic numerical computation.\n",
        "#\n",
        "# It can both gather external information AND perform\n",
        "# precise calculations, making it suitable for analytics,\n",
        "# forecasting, benchmarking, and data-driven reporting.\n",
        "#\n",
        "# This is a hybrid intelligence agent:\n",
        "#   research + reasoning + math\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "researcher_calculator = Agent(\n",
        "    role = 'Senior Research Analyst',\n",
        "    # Establishes expert-level authority in research and analysis.\n",
        "    # Encourages evidence-based reasoning and structured thinking.\n",
        "\n",
        "    goal = 'Research breakthroughs and perform data calculations for {topic}.',\n",
        "    # Dual mission:\n",
        "    # 1) Discover cutting-edge developments\n",
        "    # 2) Execute supporting numerical analysis\n",
        "    # {topic} is dynamically injected at runtime.\n",
        "\n",
        "    backstory = 'Expert analyst with a focus on 2026 tech trends and metrics.',\n",
        "    # Behavioral context shaping tone and priorities.\n",
        "    # Promotes forward-looking, metric-driven analysis.\n",
        "\n",
        "    tools = [tools['calc']],\n",
        "    # Grants access to multiple external tools:\n",
        "    # - search_tool â†’ live web research\n",
        "    # - calculator â†’ exact mathematical computation\n",
        "    # Tool chaining enables richer reasoning workflows.\n",
        "\n",
        "    llm = tools['gemini_llm'],\n",
        "    # Core language model used for synthesis and interpretation.\n",
        "\n",
        "    verbose = True,\n",
        "    # Enables detailed execution tracing.\n",
        "    # Useful for debugging tool calls and reasoning steps.\n",
        "\n",
        "    allow_delegation = True\n",
        "    # Allows the agent to delegate subtasks to other agents.\n",
        "    # Required for hierarchical or multi-agent workflows.\n",
        ")"
      ],
      "metadata": {
        "id": "k-_S25R-rmgQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NpMFsJ7cVISP"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Define AI agents for the multi-agent workflow\n",
        "# -----------------------------------------------------------\n",
        "# Each agent is configured with a professional role, a goal,\n",
        "# and a behavioral backstory. These are not decorative â€”\n",
        "# they act as structured prompts that guide how the model\n",
        "# reasons, communicates, and makes decisions.\n",
        "#\n",
        "# Both agents share the same underlying LLM but behave\n",
        "# differently due to their role configuration.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "# ---------------- Writer Agent ----------------\n",
        "# Responsible for generating the final written report.\n",
        "# This agent specializes in transforming technical research\n",
        "# into clear, engaging, and actionable content.\n",
        "\n",
        "writer = Agent(\n",
        "    role = 'Technical Content Strategist',\n",
        "    # Defines the agentâ€™s professional identity and tone.\n",
        "    # Influences writing style: analytical, structured, and persuasive.\n",
        "\n",
        "    goal = 'Write a compelling report on {topic}',\n",
        "    # Primary mission of the agent.\n",
        "    # {topic} is a dynamic placeholder that will be injected at runtime.\n",
        "\n",
        "    backstory = 'You translate complex research into simple, actionable insights.',\n",
        "    # Behavioral guidance that shapes decision-making and style.\n",
        "    # Encourages clarity, simplification, and audience-focused writing.\n",
        "\n",
        "    llm = tools['gemini_llm'],\n",
        "    # The language model engine powering the agent.\n",
        "    # All reasoning and generation are performed using this model instance.\n",
        "\n",
        "    verbose = VERBOSE\n",
        "    # Enables detailed execution logs if VERBOSE = True.\n",
        "    # Useful for debugging agent reasoning and prompt flow.\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------- Manager Agent ----------------\n",
        "# Oversees the workflow and ensures quality control.\n",
        "# Acts like a supervisor coordinating team output.\n",
        "\n",
        "manager = Agent(\n",
        "    role = 'Project Manager',\n",
        "    # Defines leadership-oriented behavior.\n",
        "    # Encourages structured planning and evaluation.\n",
        "\n",
        "    goal = 'Manage the team to deliver a perfect final report',\n",
        "    # High-level coordination objective.\n",
        "    # Focuses on outcomes, quality, and deadlines.\n",
        "\n",
        "    backstory = 'You ensure quality and delegate tasks between the researcher and writer.',\n",
        "    # Encourages delegation, review, and optimization.\n",
        "    # Guides the agent to act as a workflow orchestrator.\n",
        "\n",
        "    llm = tools['gemini_llm'],\n",
        "    # Uses the same LLM backend, but behaves differently due to role prompts.\n",
        "\n",
        "    allow_delegation = VERBOSE\n",
        "    # Controls whether the manager can assign tasks to other agents.\n",
        "    # When enabled, the manager can dynamically distribute work.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gaNsBMbAVISQ"
      },
      "outputs": [],
      "source": [
        "# Define Tasks\n",
        "tasks.append(Task(\n",
        "    description = 'Research the top 3 developments in {topic} for the year {year}.',\n",
        "    expected_output = 'A detailed bulleted list of findings.',\n",
        "    agent = researcher_1))\n",
        "\n",
        "tasks.append(Task(\n",
        "    description = 'Research the top 3 developments in {topic} for the year {year}.',\n",
        "    expected_output = 'A detailed bulleted list of findings.',\n",
        "    agent = researcher_2))\n",
        "\n",
        "tasks.append(Task(\n",
        "    description = 'Create a summary based on the research provided by the diferent researchers.',\n",
        "    expected_output = 'A 5-paragraph executive summary.',\n",
        "    agent = writer))\n",
        "\n",
        "tasks.append(Task(\n",
        "    description='Analyze the budget or numerical growth of {topic} in {year} using the calculator.',\n",
        "    expected_output='A summary of the numerical data and calculations.',\n",
        "    agent=researcher_2\n",
        "))\n",
        "\n",
        "tasks.append(Task(\n",
        "    description='Analyze the budget or numerical growth of {topic} in {year} using the calculator.',\n",
        "    expected_output='A summary of the numerical data and calculations.',\n",
        "    agent=researcher_calculator\n",
        "))\n",
        "\n",
        "math_task = Task(\n",
        "    description=\"\"\"\n",
        "        Calculate the mathematical operation: {operation}.\n",
        "    \"\"\",\n",
        "    expected_output=\"A brief report with the specific calculated growth figures.\",\n",
        "    agent=researcher_2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Crew\n",
        "\n",
        "crew = Crew(\n",
        "    agents = [researcher_1, researcher_2, writer],\n",
        "    tasks = [tasks[0], tasks[1], tasks[2]],\n",
        "    manager_agent = manager,\n",
        "    process = Process.hierarchical\n",
        ")\n",
        "\n",
        "result = crew.kickoff(\n",
        "    inputs = {\n",
        "        'topic': 'Autonomous Robotics',\n",
        "        'year': 2025})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "ROi9E2UcsKFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents = [researcher_calculator, writer],\n",
        "    tasks = [math_task],\n",
        "    manager_agent = manager,\n",
        "    process = Process.hierarchical\n",
        ")\n",
        "\n",
        "result = crew.kickoff(\n",
        "    inputs = {\n",
        "        'topic': 'Math operations',\n",
        "        'operation': '2 + 56 / 22'})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "abJb59NXsfNw",
        "outputId": "14f27f29-3e8a-4f6f-9cbe-fc1faee480c4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36mâ•­â”€\u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mExecution Traces\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[1;36mğŸ” \u001b[0m\u001b[1;36mDetailed execution traces are available!\u001b[0m                                                                    \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[37mView insights including:\u001b[0m                                                                                       \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[94m  â€¢ Agent decision-making process\u001b[0m                                                                              \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[94m  â€¢ Task execution flow and timing\u001b[0m                                                                             \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[94m  â€¢ Tool usage details\u001b[0m                                                                                         \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Execution Traces</span><span style=\"color: #008080; text-decoration-color: #008080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ” Detailed execution traces are available!</span>                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">View insights including:</span>                                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Agent decision-making process</span>                                                                              <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Task execution flow and timing</span>                                                                             <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Tool usage details</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The calculation of 56 / 22 is approximately 2.545.\n",
            "\n",
            "Therefore, 2 + 56 / 22 = 2 + 2.545 = 4.545.\n",
            "\n",
            "A brief report with the specific calculated growth figures:\n",
            "\n",
            "The calculated growth figure for the operation 2 + 56 / 22 is approximately 4.545.Would you like to view your execution traces? [y/N] (20s timeout): \n",
            "\n",
            "\n",
            "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tracing Preference Saved â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
            "â”‚                                                                              â”‚\n",
            "â”‚  Info: Tracing has been disabled.                                            â”‚\n",
            "â”‚                                                                              â”‚\n",
            "â”‚  Your preference has been saved. Future Crew/Flow executions will not        â”‚\n",
            "â”‚  collect traces.                                                             â”‚\n",
            "â”‚                                                                              â”‚\n",
            "â”‚  To enable tracing later, do any one of these:                               â”‚\n",
            "â”‚  â€¢ Set tracing=True in your Crew/Flow code                                   â”‚\n",
            "â”‚  â€¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file               â”‚\n",
            "â”‚  â€¢ Run: crewai traces enable                                                 â”‚\n",
            "â”‚                                                                              â”‚\n",
            "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
